---
title: "Training Report"
author: "Jeff Gui"
date: "1/25/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gridExtra)
source('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/bin/plot_matrix.R')
```

## Aim

The project aims at training a neural network which is able to,

- segment cell nucleus from PCNA signal,
- identify cell cycle phases according to PCNA signal features.


## Framework

The baseline ResNet101-FPN_3x_maskRCNN model is obtained from detectron2 project. The model has been trained on COCO dataset with benchmark mask AP = 38.6, box AP = 42.9.

## Schedule

1. The model was first trained on one of [Kaggle nucleus segmentation contests](https://www.kaggle.com/c/data-science-bowl-2018) dataset containing common fluorescent microscopy images and immunohistochemistry images to identify cell nucleus. There were 670 images in total with various size.  
__Augmentation__: None, __+ Class number__: 1, __Weight decay__: Yes, __Learning rate warmup__: Yes

2. Final output model from step 1 was trained on [deepcell dataset](https://www.deepcell.org/data) with fluroescent images from four cell lines. Since the dataset is in the unit of 30 tracked image frames, totally 2610 images can be grouped into 87 inter-correlated sets. Therefore, random shuffling was used when generating training input and validation data.  
__Augmentation__: None, __+ Class number__: 1, __Weight decay__: Yes, __Learning rate warmup__: Yes

3. Final outout model from step 2 was trained on 25 in-house labeled PCNA fluroescent images to identify cell nucleus and predict cell cycle phases. Because PCNA stably distributes in the nucleus during G1/G2, resembling nucleus signal in deepcell images and most images from Kaggle dataset, we labeled images with the same category ID as in the previous training. S phase and M phase were labeled as two new categories. We noted that during mitosis PCNA leaks into the cytoplasm therefore the signal is weak. Nevertheless, DIC feature of cell rounding during mitosis is obvious. Hence, two additional channels of the input were designed: 1. DIC image; 2. mask via lowered Otsu threshold that captures all true positive regions. See __Results.__ for comparsion with single grayscale input.  
__Augmentation__: Yes, __+ Class number__: 3, __Weight decay__: Yes, __Learning rate warmup__: Yes

    _(see Results. for detailed training configuration)_

\newpage

## Results

### Kaggle Nucleus

670 images were separated into 570 training set and 100 validation set. After training for 3000 iterations / __~10 epochs__, total loss converges at `0.72` with `AP50 = 83.46`

```{r, fig.retina=NULL, out.width=500, echo=FALSE}
knitr::include_graphics("/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/inspect/kaggle_demo1.png")
```

```{r, fig.retina=NULL, out.width=500, echo=FALSE}
knitr::include_graphics("/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/inspect/kaggle_demo2.png")
```

#### Configurations

```
    cfg.SOLVER.IMS_PER_BATCH = 2
    cfg.SOLVER.BASE_LR = 0.01
    cfg.SOLVER.WEIGHT_DECAY = 0.0001
    cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0
    cfg.SOLVER.GAMMA = 0.1
    cfg.SOLVER.STEPS = (1000,)
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
```

#### Outputs

Outputs generated by detectron2 logging matrix.

```{r, echo=FALSE}
BATCH_SIZE = 2
IMAGE_TRAIN = 570
IMAGE_VALID = 100
MAX_ITER = 3000
rt = process_matrix('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/train_matrix/20210125_kaggle.json')
AP = rt[['AP']]
meta = rt[['meta']]

plot_rt = plot_matrix(IMAGE_TRAIN, BATCH_SIZE, MAX_ITER, AP, meta)
p1 = arrangeGrob(plot_rt[['lc']], plot_rt[['lr']],ncol=1)
grid.arrange(plot_rt[['ap']], p1, nrow=1)
```

\newpage

### Deepcell Nucleus

2610 images were separated into 2220 training set and 390 validation set with random shuffling to avoid inter-correlation among images. After training for 1800 iterations / __~13 epochs__, total loss converges at `0.60` with `AP50 = 95.50`

```{r, fig.retina=NULL, out.width=500, echo=FALSE}
knitr::include_graphics("/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/inspect/3T3NIH.png")
```

```{r, fig.retina=NULL, out.width=500, echo=FALSE}
knitr::include_graphics("/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/inspect/HeLa.png")
```

#### Configurations

```
    cfg.SOLVER.IMS_PER_BATCH = 16
    cfg.SOLVER.BASE_LR = 0.001
    cfg.SOLVER.WEIGHT_DECAY = 0.0001
    cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0
    cfg.SOLVER.GAMMA = 0.1
    cfg.SOLVER.STEPS = (1000,)
    cfg.SOLVER.MAX_ITER = 1800
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
```

#### Outputs

Outputs generated by detectron2 logging matrix.

```{r, echo=FALSE}
BATCH_SIZE = 16
IMAGE_TRAIN = 2220
IMAGE_VALID = 390
MAX_ITER = 1800
rt = process_matrix('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/train_matrix/20210125_deepcell.json')
AP = rt[['AP']]
meta = rt[['meta']]

plot_rt = plot_matrix(IMAGE_TRAIN, BATCH_SIZE, MAX_ITER, AP, meta)
p1 = arrangeGrob(plot_rt[['lc']], plot_rt[['lr']],ncol=1)
grid.arrange(plot_rt[['ap']], p1, nrow=1, padding=2)
```

\newpage

### In-house PCNA Nucleus

25 fluorescent images were used as the training set. Random cropping and flipping augmentation was applied. Unlike previous two steps, detection class is sub-divided into G1/G2, S and M cell cycle phases. After training for 10000 iterations / __~400 epochs__, total loss converges at `1.38`.

```{r, fig.retina=NULL, out.width=400, echo=FALSE}
knitr::include_graphics("/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/inspect/pcna_demo1.png")
```

Expanding gray scale input with DIC and Otsu mask channels significantly enhances learning performance with total loss converges at `0.25`.

```{r, fig.retina=NULL, out.width=400, echo=FALSE}
knitr::include_graphics("/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/docs/trainingIp.png")
```

#### Configurations

```
    cfg.SOLVER.IMS_PER_BATCH = 1
    cfg.SOLVER.BASE_LR = 0.001
    cfg.SOLVER.WEIGHT_DECAY = 0.0001
    cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0
    cfg.SOLVER.GAMMA = 0.1
    cfg.SOLVER.STEPS = (6000,)
    cfg.SOLVER.MAX_ITER = 10000
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3

    # Augmentation
    cfg.INPUT.MIN_SIZE_TRAIN = 1000
    cfg.INPUT.MAX_SIZE_TRAIN = 1200
    cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = 'choice'
    cfg.INPUT.CROP.ENABLED = True
    cfg.INPUT.CROP.TYPE = 'relative'
    cfg.INPUT.CROP.SIZE = [0.9,0.9]
```

#### Outputs

Outputs generated by detectron2 logging matrix.

```{r, echo=FALSE}
BATCH_SIZE = 1
IMAGE_TRAIN = 25
IMAGE_VALID = 0
MAX_ITER = 10000
rt_raw = process_matrix('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/train_matrix/20210126_pcna_rawin.json')
rt_pcd = process_matrix('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/train_matrix/20210126_pcna_cls_pcd.json')
meta_raw = rt_raw[['meta']]
meta_pcd = rt_pcd[['meta']]
meta = data.frame('iteration'=meta_raw$iteration, 'raw'=meta_raw$total_loss, 'pcd'=meta_pcd$total_loss)
meta = gather(meta, key='data_type', value='loss', 2:ncol(meta))
meta$data_type = as.factor(meta$data_type)

iter_per_epoch = floor(IMAGE_TRAIN/BATCH_SIZE*100)
cut = c()
ep = iter_per_epoch
while (ep <= MAX_ITER){
  cut = c(cut, ep)
  ep = ep + iter_per_epoch
}

lr = ggplot(meta_raw) + theme_classic() +
    geom_line(aes(x=iteration, y=lr)) +
    geom_vline(xintercept=cut, linetype="dotted") +
    labs(x='Iteration', y=element_blank(), title='Learning rate')


lc = ggplot(meta, aes(x=iteration, y=loss, color=data_type)) + theme_classic() + 
    geom_line() +
    geom_vline(xintercept=cut, linetype="dotted") +
    theme(legend.position = 'bottom') +
    labs(x='Iteration', y=element_blank(), title='Total loss', fill='Data type') +
    scale_fill_discrete(labels=c("Uni", "Double"))
  

grid.arrange(lc, lr, ncol=1)
```

### Output of ResNet50

```{r, echo=FALSE}
BATCH_SIZE = 1
IMAGE_TRAIN = 25
IMAGE_VALID = 0
MAX_ITER = 7500
rt_uni = process_matrix('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/train_matrix/20210128_pcnaRawIn.json')
rt_dual = process_matrix('/Users/jefft/Desktop/Chan lab/SRTP/ImageAnalysis/PCNAdeep/train_matrix/20210128_pcnaDual.json')
meta_raw = rt_uni[['meta']]
meta_dual = rt_dual[['meta']]

meta = data.frame('iteration'=meta_raw$iteration, 'uni'=meta_raw$total_loss, 'dual'=meta_dual$total_loss)

meta = gather(meta, key='data_type', value='loss', 2:ncol(meta))
meta$data_type = as.factor(meta$data_type)

iter_per_epoch = floor(IMAGE_TRAIN/BATCH_SIZE*100)
cut = c()
ep = iter_per_epoch
while (ep <= MAX_ITER){
  cut = c(cut, ep)
  ep = ep + iter_per_epoch
}

lr = ggplot(meta_raw) + theme_classic() +
    geom_line(aes(x=iteration, y=lr)) +
    geom_vline(xintercept=cut, linetype="dotted") +
    labs(x='Iterations', y='Learning rate') +
    scale_x_continuous(breaks=c(0,2500,5000,7500))

meta$data_type = as.factor(meta$data_type)
meta$loss = as.numeric(meta$loss)
lc = ggplot(meta, aes(x=iteration, y=loss)) + theme_classic() + 
    geom_line(aes(color=data_type), size=1) +
    geom_vline(xintercept=cut, linetype="dotted") + 
    labs(x='Iterations', y='Total loss') +
    theme(legend.position = 'bottom', legend.spacing = unit(0, "cm")) +
    scale_color_manual(name="Training data", labels=c('DIC + mCherry (I)','mCherry (I)'), values = c("#0073C2FF", "#EFC000FF")) +
    scale_x_continuous(breaks=c(0,2500,5000,7500))

grid.arrange(lc, lr, ncol=1)
```

```{r}
BATCH_SIZE = 2
IMAGE_TRAIN = 156  # 10A_1: 35, 10A_2: 35, 231: 31, mitosis: 55
IMAGE_VALID = 0
MAX_ITER = 12000
rt_uni = process_matrix('/Users/jefft/Desktop/Chan lab/GrantImage/deep_cell/dual-tri10A.json')
meta_raw = rt_uni[['meta']]

meta = data.frame('iteration'=meta_raw$iteration, 'all'=meta_raw$total_loss)

meta = gather(meta, key='data_type', value='loss', 2:ncol(meta))
meta$data_type = as.factor(meta$data_type)

iter_per_epoch = floor(IMAGE_TRAIN/BATCH_SIZE*50)
cut = c()
ep = iter_per_epoch
while (ep <= MAX_ITER){
  cut = c(cut, ep)
  ep = ep + iter_per_epoch
}

lr = ggplot(meta_raw) + theme_classic() +
    geom_line(aes(x=iteration, y=lr)) +
    geom_vline(xintercept=cut, linetype="dotted") +
    labs(x='Iterations', y='Learning rate') +
    scale_x_continuous(breaks=c(0, cut))

meta$data_type = as.factor(meta$data_type)
meta$loss = as.numeric(meta$loss)
lc = ggplot(meta, aes(x=iteration, y=loss)) + theme_classic() + 
    geom_line(aes(color=data_type), size=1) +
    geom_vline(xintercept=cut, linetype="dotted") + 
    labs(x='Iterations', y='Total loss') +
    theme(legend.position = 'bottom') +
    scale_color_manual(name="Training data", labels=c('DIC + mCherry (II)'), values = c("#0073C2FF")) +
    scale_x_continuous(breaks=c(0, cut))
```

```{r}
rt_uni = process_matrix('/Users/jefft/Desktop/Chan lab/GrantImage/deep_cell/dual-tri10A.json')
AP = rt_uni[['AP']]
ggplot(AP, aes(x=iteration, y=value)) + theme_classic() +
  geom_line(aes(color=AP_measures)) +
  labs(x='Iterations',y='AP (%)') +
  scale_y_continuous(breaks=seq(0,100,10)) +
  scale_color_discrete(name="Measure type")
```


